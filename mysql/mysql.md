# MySql架构

## 连接MySql大概过程

![image-20210413151039244](img/image-20210413151039244.png)

> `JDBC`流程如下
>
> ~~~java
>  public static void main(String[] args) throws SQLException, ClassNotFoundException {
>         Class.forName("com.mysql.cj.jdbc.Driver");
>         Connection conn = DriverManager.getConnection("jdbc:mysql://127.0.0.1:3306/imooc", "root", "root");
>         Statement statement = conn.createStatement();
>         statement = statement;
>         String sql = "insert into user(loginName,userName,password,sex)values('tom123','tom','123456',1)";
>         int result = statement.executeUpdate(sql);
>   }
> ~~~



网络连接由线程处理：当数据库服务器连接池接受到网络请求时，会分配一个工作线程去进行处理

## MySql处理流程

![image-20210414111703139](img/image-20210414111703139.png)





### SQL接口：负责处理接收到的SQL语句

​	MySql工作线程从网络连接中读取出SQL语句后，会将其交给SQL接口去执行。

​	**SQL接口**：`是一套执行SQL语句的接口，专门用于执行我们发送给MySql的增删改查语句`

### 查询解析器：让MySql看懂sql语句

​	**Parser(查询解析器)**：`按照既定的sql语法规则，对sql语句进行解析，理解sql语句要做什么事情`

### 查询优化器：选择最优查询路径

​	**Optimizer(查询优化器)**：`针对编写的sql，生成所谓查询路径树，从中选择一条最优路径出来`

​	相当于告诉你，你应该按照什么样的步骤和顺序，去执行那些操作，然后一步一步的把sql语句给完成

### 执行器：根据执行计划调用存储引擎接口

​	`执行器会根据优化器生成的一套执行计划，然后不停的调用存储引擎的各种接口去完成sql语句的执行计划`

### 存储引擎接口：真正执行sql语句

​	MySql的架构设计中，SQL接口，解析器，优化器都是通用的，仅是一套组件而已。但存储引擎是由各种各样的，如InnoDB，MyISAM等，我们是可以选择使用那种存储引擎来负责具体sql执行的。

​	`存储引擎就是执行sql语句的，他会按照一定步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等等`





# InnoDB

​	以一条update语句为例，初步了解InnoDB存储引擎的架构设计

​	update user set name = 'xxx' where id = 10	这条sql首先会通过数据库连接发送到MySql上，然后经过SQL接口，解析器，优化器，执行器几个环节，解析SQL语句，生成执行计划，接着由执行器负责计划的执行，调用InnoDB存储引擎的接口去执行

## 更新语句大致流程

---



### 	缓存池（Buffer Pool）

​		引擎执行更新语句时，会先判断id=10的数据是否存在于缓冲池中。如果不存在，则会从磁盘中加载数据，并且会对这行记录加独占锁

> Buffer Pool是一个放在内存中的组件，非常重要。其中放有缓存的数据，便于以后查询时，可以考虑直接从缓冲中获取。

### 	undo日志

​		如果id为10的数据name为zhangsan，先将其更新为xxx。那需要把这条记录原来的值（zhangsan，id为10）这些信息，写入到undo日志文件中去

> 考虑到未来可能要回滚数据，需要将更新前的值写入到undo日志文件中

### 更新buffer pool中数据

​		在将磁盘文件中加载到缓冲池后，同时加锁之后，并将修改前的数据写入到undo日志文件中之后。就可以正式更新这行记录了。更新时，先更新buffer pool中的数据。此时缓存数据和磁盘数据不一致

### Redo Log Buffer

​		为了避免MySql宕机，导致内存中数据丢失，需要把对内存所作修改写入到Redo Log Buffer中去，这也是内存中的一个缓冲区，使用了存放redo日志的。``redo日志就是记录对数据做了什么修改``

​		如果此时MySql宕机，此时内存中的数据全部丢失，但是由于事务并没有更新，所以磁盘上的数据依旧是旧数据

### Redo落盘

​		提交事务时，需要根据一定策略将redo日志从redo log buffer中刷入磁盘。这个策略是通过 **innodb_flush_log_at_trx_commit** 来进行配置的。其刷盘策略有三种

> 参数为0：提交事务时，不会将redo log buffer中数据刷入磁盘。如果此时MySql宕机了，那么内存中数据会丢失
>
> 参数为1：提交事务时，必须把redo log从内存中刷到磁盘文件中去，只要提交事务成功，那么redo log就必然在磁盘里了。此时MySql若宕机，那么内存中的数据虽然丢失，但是redo log 文件得到保存，MySql可以根据redo日志去进行恢复
>
> 参数为2：提交事务时，把redo日志写入到磁盘os cache缓存中，等待刷入到磁盘中去。如此时MySql宕机，并且redo文件还停留带os cacha中，那么数据会丢失

​		因此，redo日志刷盘策略一般都选为1，保证事务提交之后，数据不会丢失

因为数据库的每一次更新SQL语句，都必然涉及到多个磁盘随机读取数据页的操作，也会涉及到一条redo log日志文件顺序写的操作。所以磁盘读写的IOPS指标，就是每秒可以执行多少个随机读写操作，以及每秒可以读写磁盘的数据量的吞吐量指标，就是每秒可以写入多少redo log日志，整体决定了数据库的并发能力和性能。

### Binlog日志

> ​	redo log是一种**偏向物理性质的重做日志**，他里面记录的是类似这样的东西：对那个数据页中的什么记录，进行了什么修改。并且redo log是InnoDB存储引擎特有的
>
> ​	而binlog叫归档日志，**记录的是偏逻辑性的日志**，类似于：对user表中的id=10的行数据进行了更新，更新后的值是什么，binlog是mysql server自己的日志文件，不是InnoDB所特有的

​	在提交事务的同时，也会把这次更新对应的binlog文件写入到磁盘中去。对于binlog也有不同的刷盘策略，由参数 **sync_binlog** 控制。

> 参数为0：提交事务时，将binlog日志写入磁盘os cache中，等待刷入磁盘。此时若宕机，数据会丢失。0为默认值
>
> 参数为1：提交事务时，强制将binlog日志写入到磁盘中去。

### 基于binlog和relo log完成事务提交

​		当binlog写入到磁盘文件中后，接着就完成最终的事务提交，此时会将更新对应的binlog文件名称和此次更新的binlog日志在文件中的位置都写入到redo log日志文件中去，同时在redo log日志文件里写入一个commit标记。此时，才算完成了事务的提交

​		在redo log中写入commit标记的意义在于：`保持redo log和binlog的一致。`因为只有redo log和binlog一致，才能确认本次事务提交成功。

### 后台IO线程将内存中数据刷入磁盘

​		MySql后台有一个IO线程，会在之后某时间，随机的将内存buffer pool中的修改后的脏数据给刷回到磁盘中的数据文件中去。哪怕宕机也不影响，因为redo log和binlog中留有记录，可自行恢复





![image-20210415151815139](img/image-20210415151815139.png)



**执行器是非常核心的一个组件，负责跟存储引擎配合完成一个SQL语句在磁盘和内存层面的全部数据更新操作**

在执行更新时，每条SQL语句，都会对应修改buffer pool中的缓存数据，写undo日志，写redo log buffer 等步骤；在提交事务时，一定会将redo log刷入磁盘，binlog刷入磁盘，完成redo log中的commit标记；最后，再由后台IO线程随机的将buffer pool中的脏数据刷入到磁盘中





# 生产层面

8核16G，一般每秒扛一两千请求是没有问题的

16核32G，每秒三四千一般也没问题

数据库的磁盘最后使用SSD固态硬盘（数据库需要执行IO操作）



QPS(QUERY PER SECOND)：每秒处理多少请求。对数据库而言，可理解为每秒处理多少SQL语句

TPS(TRANSCATION PER SECOND)：每秒可处理的事务量。可理解为每秒处理多少事务提交或回滚

## 压测指标

### IO相关

- **IOPS**：这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机IO读写请求。

	这个指标是很关键的，因为之前我们在数据库架构原理中讲解过，你在内存中更新的脏数据库，最后都会由后台IO线程在不确定的时间，刷回到磁盘里去，这就是随机IO的过程。如果说IOPS指标太低了，那么会导致你内存里的脏数据刷回磁盘的效率就会不高。

- **吞吐量**：指机器的磁盘存储每秒可以读写多少字节的数据量

	这个指标也是很关键的，因为大家通过之前的学习都知道，我们平时在执行各种SQL语句的时候，提交事务的时候，其实都是大量的会写redo log之类的日志的，这些日志都会直接写磁盘文件。所以一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。一般来说我们写redo log之类的日志，都是对磁盘文件进行顺序写入的，也就是一行接着一行的写，不会说进行随机的读写，那么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。

- **latency**：指向磁盘中写入一条数据的延迟

	这个指标同样很重要，因为我们执行SQL语句和提交事务的时候，都需要顺序写redo log磁盘文件，所以此时你写一条日志到磁盘文件里去，到底是延迟1ms，还是延迟100us，这就对你的数据库的SQL语句执行性能是有影响的。一般来说，当然是你的磁盘读写延迟越低，那么你的数据库性能就越高，你执行每个SQL语句和事务的时候速度就会越快。

### 其他指标

- **CPU负载**：CPU负载是一个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标都还正常，但是此时CPU负载特别高，那么也说明你的数据库不能继续往下压测更高的QPS了，否则CPU是吃不消的。
- **网络负载**：这个主要是要看看你的机器带宽情况下，在压测到一定的QPS和TPS的时候，每秒钟机器的网卡会输入多少MB数据，会输出多少MB数据，因为有可能你的网络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，网卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了。
- **内存负载**：这个就是看看在压测到一定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过高了，说明也不能继续压测下去了。

### 压测工具和监控

​	[压测工具sysbench](https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e383c5357307_MjhluwMb/1?from=p_5e0c2a35dbbc9_MNDGDYba&type=6)

​	[监控工具Prometheus和Grafana](https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e398efe3b8f9_XZOAxAmQ/1?from=p_5e0c2a35dbbc9_MNDGDYba&type=6)

​	

# Buffer Pool

buffer pool是数据库中必须要搞懂的一个核心组件，因为增删改查操作首先就是针对这个内存中的Buffer Pool里的数据执行的，同时配合了后续的redo log，刷磁盘等机制和操作

## Buffer Pool的数据结构

Buffer Pool默认大小为128MB，可以通过配置修改。本质就是数据库中的一个内存组件，由一大堆缓存页和描述数据块组成，然后加上各种链表(free,flush,lru)辅助其运行

~~~shell
[server]
innodb_buffer_pool_size=2147483648
~~~



### 数据页和缓存页

MySql对数据抽象出了一个**数据页**的概念，他将很多**行数据**放在了一个数据页中，每一页数据中放了很多行数据。所以buffer pool中的存放的是一个个的数据页

默认情况下，磁盘中存放的数据页的大小是16KB，也就是说一页数据包含了16KB的内容。Buffer Pool中存放的页数据又称之为缓存页，一个缓存页的大小和一个数据页的大小是一一对应的。

### 缓存页中的描述信息

对于每个**缓存页**，都会有一个**描述信息**，这个描述信息可以大体确认是用来描述这个缓存页的，一般包含：这个数据页的表空间，数据页的编号，这个缓存页在Buffer Pool中的内存地址以及一些别的信息。这些描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面。如下图

![image-20210415165620384](img/image-20210415165620384.png)

Buffer Pool中的描述数据大概相当于缓存页的大小的5%左右。假设设置的buffer pool大小是128MB，那么实际上真正的大小可能有130MB，因为他里面还含有每个缓存页中的数据

### Buffer Pool的初始化

数据库启动时，便会按照配置的buffer pool大小，再稍微加大一点，去向操作系统申请一块内存空间，作为buffer pool的内存区域。内存区域申请完毕后，数据库就会按照默认的缓存页的16KB大小和对应的800字节左右的描述数据的大小，在Buffer Pool中划分出一个一个的缓存页和对于的描述数据。但此时缓存页都是空的，什么都没有

## Free链表

### 链表结构

Buffer Pool中有一个**Free链表**设计，他是一个**双向链表结构**，每个节点就是一个**空闲缓存页的描述数据块的地址**，即只要有一个缓存页是空闲的，那么他的描述数据块就会被放入到这个free链表中

![image-20210415172352892](img/image-20210415172352892.png)

free链表中还有一个基础节点，指向链表的头尾节点，里面还存储了链表中有多少个描述数据块的节点，即空闲缓存页

### 占用空间

free链表本身，就是由Buffer Pool中的描述数据块组成，每个描述数据块中都有两块指针，free_pre和free_netx。分别指向自己的上一个free链表的节点，以及下一个free链表的节点。

对于free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面存放了free链表的头节点的地址，尾节点的地址，还有free链表中当前有多少节点

### 将数据读入到Buffer Pool

1. 首先从free链表中获取一个描述数据块，并根据数据库找到缓存页
2. 将磁盘上的数据读取到对应的缓存页中去，同时将相关描述信息写入到缓存页的描述数据块中。比如数据页所属表空间等信息。
3. 最后把描述数据库从free链表中去除

### 判断数据页是否缓存

`数据库中还会有一个哈希表数据结构，他会用表空间+数据页号，作为一个key，然后缓存页地址作为value`

当要使用数据页的时候，通过“表空间+数据页号”作为key去哈希表中查询一下，如果没有就读取数据页，如果有了，就说明已经缓存了

![image-20210416150325751](img/image-20210416150325751.png)

## Flush链表

结构和free链表类似，也是通过缓存页的描述数据块中的两块指针，让被修改过的缓存页的描述数据块，组成一个双向链表。凡是修改过的缓存页，都会将其数据块加入到flush链表中。flush的意思就是脏页，后续都是要将其flush刷新到磁盘上去的。

设计flush链表就是为了能够快速的将脏数据页中的数据刷回到磁盘中去。在更新缓存页的时候，通过变换缓存页中的描述数据块flush链表的尾指针，就可以把脏页的描述数据块组成一个双向链表，即flush链表，而且flush链表的基础节点会指向起始节点和尾巴节点。



## 缓存页的淘汰

如果所有的缓存页都被塞了数据，此时无法从磁盘上加载新的数据页到缓存页中去。那么就要淘汰一些缓存页——`即把一个缓存中修改过的数据，刷入到磁盘中去，然后将缓存页清空，再把新的数据页加载到空闲的缓存页中去`

### 缓存命中率以及LRU链表

淘汰缓存页时应尽可能选择使用率较少的缓存页，因此需要知道那些缓存页经常被访问，那些缓存页很少被访问。此时需要引入**LRU链表(Least Recently Used，最少使用)。**其数据结构和之前的Free链表，Flush链表类似，都是一个双向链表，节点均指向缓存页的描述数据块的地址



### 原始的LRU淘汰机制

> 大致工作原理：当我们从磁盘中**加载一个数据页到缓存页**时，就将这个缓存页的描述数据放入到LRU链表头部去，那么只有有数据的缓存页，都会在LRU链表中，而且最近被加载数据的缓存页，都会放到LRU链表的头部去。假设某个缓存页的描述数据在LRU链表的尾部，后续只要查询了或修改了这个缓存页，也会把这个缓存页挪动到LRU链表的头部，也就是**最近被访问过的缓存页，一定在LRU链表头部**
>
> 因此需要淘汰缓存页时，可以优先从LRU链表尾部进行淘汰

但这样的方式因为MySql的预读机制存在巨大隐患。

预读机制：当从磁盘上加载数据页的时候，MySql会连带着把这个数据页的相邻的其他数据页，都加载到缓存中去。

![image-20210416154211877](img/image-20210416154211877.png)

如果没有空闲缓存页了，此时加载新的数据页，就会将LRU链表尾部的数据淘汰。但这样是不合理的，毕竟其数据是有人访问的，而预读机制带入的数据页可能无人访问

> 一般而言，有两种情况可能触发MySql的预读机制
>
> - 有一个参数是innodb_read_ahead_threshold，他的默认值是56，意思就是如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓存里去
> - 如果Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去。这个机制是通过参数innodb_random_read_ahead来控制的，他默认是OFF，也就是这个规则是关闭的
>
> 预读机制可以一定程度上优化性能。如果你顺序读取很多数据页，MySql会判断可能会接着顺序读取后面的数据页。那么其提前读取到Buffer Pool中，后续读取就会方便很多

还有一种可能导致频繁被访问的缓存页被淘汰的情景：**全表扫描**（select *）

此时如果没where条件，那么会将表里全部数据页都从磁盘加载到Buffer Pool中去。此时LRU链表尾部，可能全部都是之前经常被访问的缓存页。此时进行淘汰时，就会将频繁访问的数据页给淘汰掉。

### 基于冷热数据分离思想设计LRU

真正的MySql在设计LRU链表时，采取的实际是**冷热数据分离**的思想。之前的问题，都是由于所有缓存页全部混在一个LRU链表中导致的

真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据。冷热数据比例由**innodb_old_blocks_pct**参数控制的，默认是37，即冷数据占比37%

**当数据页第一次加载到缓存时**：数据页第一次被加载到缓存时，缓存页会被放在**冷数据区域的链表头部**

**冷数据区域缓存何时被放入热数据区域**：**innodb_old_blocks_time 参数**，默认值是1000，即1000ms。也就是说必须是一个数据页被加载到缓存页之后，在1s之后，访问这个缓存页，才会被挪动到热数据区域的链表头部去

![image-20210416161307127](img/image-20210416161307127.png)

这样设计的话，预读机制以及全表扫描加载进来的一大批缓存页，都会放在LRU链表的冷数据区域的前面位置。而那些频繁访问的缓存页都被放在热数据区域。淘汰缓存时，直接淘汰冷数据区域尾部的缓存页，刷入磁盘即可。

在这样的设计机制下，原始的LRU淘汰机制的问题基本都被解决掉了。

`因为那种预读机制以及全表扫描机制加载进来的数据页，大部分都会在1s之内访问一下，之后可能就再也不访问了，所以这种缓存页基本上都会留在冷数据区域里。然后频繁访问的缓存页还是会留在热数据区域里。当你要淘汰缓存的时候，优先就是会选择冷数据区域的尾部的缓存页，这就是非常合理的了！他不会让刚加载进来的缓存页占据LRU链表的头部，频繁访问的缓存页在LRU链表的尾部，淘汰的时候淘汰尾部的频繁访问的缓存页了！`

**热数据区域的优化**：LRU链表中的热数据区域的访问规则进行了优化，即只有在热数据区域的后3/4区域的缓存页被访问了，才会移动到链表头部去，如果是前面1/4的区域被访问，是不会移动到链表头部的。这样减少了链表的移动。

### 定时将LRU尾部缓存页刷入磁盘

并不是在缓存页满时，才会将LRU冷数据区域尾部的缓存页刷入磁盘。而是有一个后台线程，会运行一个定时任务，每隔一段时间就会把LRU链表的冷数据尾部的缓存页刷入到磁盘中，清空缓存页，并将其加入Free链表中

### 把Flush链表的缓存页刷入磁盘

仅将LRU冷数据区域缓存页刷入磁盘是不够的，后台线程也会在**MySql不繁忙的时候，将flush链表中的缓存页刷入磁盘中**，这样修改过的数据，迟早也会刷入磁盘。只要flush链表的缓存页被刷入磁盘，那么缓存页也会从flush链表和lru链表中移除，然后加入到free链表中



### 总结

总之，MySQL在执行CRUD的时候，首先就是大量的操作缓存页以及对应的几个链表。然后在缓存页都满的时候，必然要想办法把一些缓存页给刷入磁盘，然后清空这几个缓存页，接着把需要的数据页加载到缓存页里去！

你的MySQL的内核参数，应该如何优化，优化哪些地方的行为，才能够尽可能的避免在执行CRUD的时候，经常要先刷一个缓存页到磁盘上去，才能读取一个磁盘上的数据页到空闲缓存页里来？

> 如果要避免上述问题，就要避免缓存页频繁的使用完毕。这里的关键点就在于buffer pool的大小（程序对于缓存页是使用，以及定时线程释放缓存页的过程很难去控制）
>
> buffer pool的大小以及buffer pool的数量，这些参数需要用心的设置和优化，因为他对MySql的性能和并发能力，由较大的影响。



## Buffer Pool的优化

### 多个Buffer Pool

多线程并发访问Buffer Pool时，如果访问的是一些共享数据，那么必然会进行锁操作。因此如果并发请求高的话，性能会受到影响

因此可以设置多个Buffer Pool来优化并发能力。MySql默认规则是，如果给Buffer Pool分配的内存小于1GB，那么就会分配一个Buffer Pool。如果分配的内存大，那么就可以设置多个Buffer Pool

~~~shell
# buffer pool总大小为8GB，4个buffer pool实例
[server]
innodb_buffer_pool_size = 8589934592
innodb_buffer_pool_instances = 4
~~~

这样多线程并发性能就会得到很大的提高

![image-20210416173751720](img/image-20210416173751720.png)

### 基于chunk机制动态调整Buffer Pool大小（不常用）

Buffer Pool是由很多**chunk**组成的，每个大小是由 **innodb_buffer_pool_chunk_size** 参数控制的，默认值是128MB。每个Buffer Pool里的每个chunk里就是一系列的描述数据块和缓存页，多个chunk共享一套free,flush,lru链表

![image-20210416174234597](img/image-20210416174234597.png)

基于chunk机制，就可以动态的调整buffer pool的大小了。如果需要增加Buffer Pool的大小，那么可以申请一系列的128MB大小的chunk就可以了，只要每个chunk是连续到128MB内存就可以，然后将申请到的chunk内存分配给Buffer Pool即可



## Buffer Pool的参数设置

一般buffer pool大小为机器内存的50%-60%之间即可

Buffer Pool总大小=（chunk大小 * buffer pool数量）的2的倍数

## SHOW ENGINE INNODB STATUS

![image-20210419094438495](img/image-20210419094438495.png)

![image-20210419094451591](img/image-20210419094451591.png)

## 总结

数据库在生产环境运行时，需要根据机器的内存设置合理的buffer pool大小，然后设置buffer pool的数量。这样的话，可以尽可能的保证数据库的高性能和高并发能力。

在线上运行的时候，buffer pool是由多个的，每个buffer pool中多个chunk共用一套链表数据结构。执行crud的时候，会不停的加载磁盘上的数据页到缓存页中，然后查询和更新缓存中的数据，同时维护一系列的链表结构。

然后后台线程定时根据lru链表和flush链表，去将一批缓存页刷入磁盘释放掉这些缓存页，同时更新free链表

如果执行curd时发现缓存页都满了，无法加载自己需要的数据页进行缓存，此时就将lru链表冷数据区域的缓存页刷入磁盘，然后加载自己需要的数据页进来。

大致原理就是如此。





# 物理数据结构

> 为何不直接更新磁盘上的数据——磁盘随机读写性能太差，如果直接更新磁盘文件，必然会导致数据无法承受高并发
>
> 为何进入数据页概念—— 一条一条加载数据到内存更新，效率太低。不如将数据组织成一页一页的概念，每次加载数据时，至少加载一页甚至多页数据。可以说**页**就是数据库的最小数据单位，默认为16KB大小。磁盘和内存直接的交换通过数据页来执行



## MySql物理存储格式

### 行格式

对一个表指定他的行存储格式是什么样的。eg：CREATE TABLE table_name (columns) ROW_FORMAT=COMPACT/ALTER TABLE table_name ROW_FORAMT=COMPACT

对于每一行数据，存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上他这一行数据的每一列的具体的值，这就是所谓的行格式。大致形式如下

> 变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......

其他几种行格式都大同小异。

### 变长字段在磁盘的存储

在存储每一行数据时，都保存其变长字段的长度列表，这样才能解决读取问题。如果有多个变长字段，则长度排放是逆序的。如果hello是VARCHAR(10)类型的变长字段的值，那么其在磁盘存储时，结构可能是这样的 0x05 null值列表 数据头 hello ...

> create table custom（name VARCHAR(10) NOT NULL  ,  address VARCHAR(20)  ,  gender CHAR(1)  ,  job VARCHAR(30)  ,  school VARCHAR(50)）ROW_FORMAT=COMPACT;
>
> 假设数据为 jack NULL m NULL xx_school。
>
> 如果变长字段为null值，就不用在变长字段列表里存放值长度了，上述数据中，只有name和school两个字段有值。将其长度按照逆序放在变长字段长度列表中即可      
>
> 0x09 0x04 NULL值列表 头信息...
>
> 

### NULL字段值在磁盘的存储

NULL值列表即一行数据中可能有的字段值为NULL，比如name字段，如果允许为NULL值，并且在实际存储时也没有赋值，那其字段值就为NULL。

但是NULL值在实际存储时，是不会按照字符串形式存放在磁盘上浪费空间的，null实际是以二进制bit位来存储的。

Null值列表是允许值为Null，只要是允许为null的字段，在NULL值列表中都会有一个bit位，bit值为1说明是NULL，为0说明不是NULL

 jack NULL m NULL xx_school数据中有4个字段允许为NULL，其中有两个为null，两个不为null。则4个bit位：1010。但其实逆序存放，实际上是0101。并且NULL值列表存放时，不会仅仅是4个bit位，他一般起码是8个bit位的倍数，不足8位就补0。所以实际存储时类似下面这种形式

**0x09 0x04 00000101 数据头信息 column01=value1，column02=value2，column0n=voluen......**

### 数据头的存储

40个bit为中，第一位和第二位都是预留位，没任何含义

第三个bit位是：**delete_mask**，其标识本行数据是否被删除

第四个bit位是：min_rec_mask，是否是B+Tree每一层的非叶子节点的最小值

接下来的4个bit位是：n_owned，记录数

接下来的13个bit位是：heap_no，代表当前这行数据在记录堆里的位置

接下来3个bit位的record_type，即这行数据的类型：0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据

最后是16bit位的next_record，指向下一条数据的指针

0x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school

### 实际数据的存储

实际上字符串是根据数据库指定的字符集编码，进行编码后再存储的，所以一行数据可能如下

0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262

在实际存储时，会在其真实数据部分加入一些隐藏字段：

- DB_ROW_ID：行唯一标识，数据库内部设置的一个标识，不是主键ID字段。如果没有指定主键和unique key唯一索引，他就会在内部自动加ROW_ID作为主键
- DB_TRX_ID：事务id，和事务有关
- DB_ROLL_PTR：回滚指针，用来进行事务回滚。

如果加上隐藏字段，实际一行数据可能如下

0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR）  616161 636320 6262626262

### 行溢出

数据页的默认大小为16KB，如果一行的数据存储内容太多(blob，text这种类型字段都有可能出现溢出)，一个数据页都放不下了，此时只能溢出这个数据页，把数据溢出存放到其他数据页中，那些数据页就叫做溢出页

![image-20210419155633644](img/image-20210419155633644.png)

## 数据页的结构

一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部。

![image-20210419160536834](img/image-20210419160536834.png)

其中文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节。

行数据会插入到缓存页的空闲区域（数据页和缓存页是一一对应的）中，并最终被刷入到磁盘中

## 表空间和数据区

平时创建的表，都有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的磁盘数据空间。在物理层面，表空间就是对应一些磁盘上的数据文件。有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个“表名.ibd”数据文件。

一个表空间里的数据页太多了，不便于管理，于是引入**数据区（extent）**的概念，一个数据区对应着连续的64个数据页，每个数据页是16KB，所以一个数据区是1mb，然后256个数据区被划分为一组。

**对应表空间而言，他的第一组数据区的前三个数据页都是固定的，存放了一些描述性的数据。表空间的其他组数据区的第一个数据区的前两个数据页，也是存放特殊信息的**

**我们平时创建的那些表都是有对应的表空间的，每个表空间就是对应了磁盘上的数据文件，在表空间里有很多组数据区，一组数据区是256个数据区，每个数据区包含了64个数据页，是1mb**

当我们需要执行crud操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用。

![image-20210419162102028](img/image-20210419162102028.png)

# IO调度

## LINUX层面读写

简单来说，Linux的存储系统分为VFS层、文件系统层、Page Cache缓存层、通用Block层、IO调度层、Block设备驱动层、Block设备层，如下图：

![image-20210419165915585](img/image-20210419165915585.png)

当MySQL发起一次数据页的随机读写，或者是一次redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给Linux操作系统的VFS层。这一层的作用，就是根据你是对哪个目录中的文件执行的磁盘IO操作，把IO请求交给具体的文件系统。

举个例子，在linux中，有的目录比如/xx1/xx2里的文件其实是由NFS文件系统管理的，有的目录比如/xx3/xx4里的文件其实是由Ext3文件系统管理的，那么这个时候VFS层需要根据你是对哪个目录下的文件发起的读写IO请求，把请求转交给对应的文件系统，如下图所示。

接着文件系统会先在Page Cache这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读写，如果没有就继续往下一层走，此时这个请求会交给通用Block层，在这一层会把你对文件的IO请求转换为Block IO请求。

接着IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这一层里默认是用CFQ公平调度算法的，也就是说，可能假设此时你数据库发起了多个SQL语句同时在执行IO操作。有一个SQL语句可能非常简单，比如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的一个block里的数据就可以了。但是有的SQL语句，比如说select * from xx where xx1 like "%xx%"可能需要IO读取磁盘上的大量数据。那么此时如果基于公平调度算法，就会导致他先执行第二个SQL语句的读取大量数据的IO操作，耗时很久，然后第一个仅仅更新少量数据的SQL语句的IO操作，就一直在等待他，得不到执行的机会。

所以在这里，**其实一般建议MySQL的生产环境，需要调整为deadline IO调度算法，他的核心思想就是，任何一个IO操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。**

此时IO请求被转交给IO调度层

最后IO完成调度之后，就会决定哪个IO请求先执行，哪个IO请求后执行，此时可以执行的IO请求就会交给Block设备驱动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，如下图所示。然后硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上面的层级反向依次返回，最终MySQL可以得到本次IO读写操作的结果。

## RAID存储架构

RAID就是一个磁盘冗余阵列，可以大致理解为用来**管理机器里的多块磁盘的一种磁盘阵列技术**。有了它，在向磁盘中读写数据时，他会告诉你应该在那块磁盘上读写数据。并且其还实现了**数据冗余机制**，所以其实有的RAID磁盘冗余阵列技术里，是可以把你写入的同样一份数据，在两块磁盘上都写入的，这样可以让两块磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的，不需要你操心。

![image-20210419170918602](img/image-20210419170918602.png)

服务器使用多块磁盘组成的RAID阵列的时候，一般会有一个RAID卡，这个RAID卡是带有一个缓存的，这个缓存不是直接用我们的服务器的主内存的那种模式，他是一种跟内存类似的SDRAM，当然，你大致就认为他也是基于内存来存储的吧！然后我们可以把RAID的缓存模式设置为write back，这样的话，所有写入到磁盘阵列的数据，先会缓存在RAID卡的缓存里，后续慢慢再写入到磁盘阵列里去，这种写缓冲机制，可以大幅度提升我们的数据库磁盘写的性能。

RAID卡一般都配置有自己独立的锂电池或者是电容，如果服务器突然掉电了，无法接通电源了，RAID卡自己是基于锂电池来供电运行的，然后他会赶紧把缓存里的数据写入到阵列中的磁盘上去。

# redo和undo

