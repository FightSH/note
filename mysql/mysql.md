# MySql架构

## 连接MySql大概过程

![image-20210413151039244](img/image-20210413151039244.png)

> `JDBC`流程如下
>
> ~~~java
> public static void main(String[] args) throws SQLException, ClassNotFoundException {
>      Class.forName("com.mysql.cj.jdbc.Driver");
>      Connection conn = DriverManager.getConnection("jdbc:mysql://127.0.0.1:3306/imooc", "root", "root");
>      Statement statement = conn.createStatement();
>      statement = statement;
>      String sql = "insert into user(loginName,userName,password,sex)values('tom123','tom','123456',1)";
>      int result = statement.executeUpdate(sql);
> }
> ~~~



网络连接由线程处理：当数据库服务器连接池接受到网络请求时，会分配一个工作线程去进行处理

## MySql处理流程

![image-20210414111703139](img/image-20210414111703139.png)





### SQL接口：负责处理接收到的SQL语句

​	MySql工作线程从网络连接中读取出SQL语句后，会将其交给SQL接口去执行。

​	**SQL接口**：`是一套执行SQL语句的接口，专门用于执行我们发送给MySql的增删改查语句`

### 查询解析器：让MySql看懂sql语句

​	**Parser(查询解析器)**：`按照既定的sql语法规则，对sql语句进行解析，理解sql语句要做什么事情`

### 查询优化器：选择最优查询路径

​	**Optimizer(查询优化器)**：`针对编写的sql，生成所谓查询路径树，从中选择一条最优路径出来`

​	相当于告诉你，你应该按照什么样的步骤和顺序，去执行那些操作，然后一步一步的把sql语句给完成

### 执行器：根据执行计划调用存储引擎接口

​	`执行器会根据优化器生成的一套执行计划，然后不停的调用存储引擎的各种接口去完成sql语句的执行计划`

### 存储引擎接口：真正执行sql语句

​	MySql的架构设计中，SQL接口，解析器，优化器都是通用的，仅是一套组件而已。但存储引擎是由各种各样的，如InnoDB，MyISAM等，我们是可以选择使用那种存储引擎来负责具体sql执行的。

​	`存储引擎就是执行sql语句的，他会按照一定步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等等`





# InnoDB

​	以一条update语句为例，初步了解InnoDB存储引擎的架构设计

​	update user set name = 'xxx' where id = 10	这条sql首先会通过数据库连接发送到MySql上，然后经过SQL接口，解析器，优化器，执行器几个环节，解析SQL语句，生成执行计划，接着由执行器负责计划的执行，调用InnoDB存储引擎的接口去执行

## 更新语句大致流程

---



### 	缓存池（Buffer Pool）

​		引擎执行更新语句时，会先判断id=10的数据是否存在于缓冲池中。如果不存在，则会从磁盘中加载数据，并且会对这行记录加独占锁

> Buffer Pool是一个放在内存中的组件，非常重要。其中放有缓存的数据，便于以后查询时，可以考虑直接从缓冲中获取。

### 	undo日志

​		如果id为10的数据name为zhangsan，先将其更新为xxx。那需要把这条记录原来的值（zhangsan，id为10）这些信息，写入到undo日志文件中去

> 考虑到未来可能要回滚数据，需要将更新前的值写入到undo日志文件中

### 更新buffer pool中数据

​		在将磁盘文件中加载到缓冲池后，同时加锁之后，并将修改前的数据写入到undo日志文件中之后。就可以正式更新这行记录了。更新时，先更新buffer pool中的数据。此时缓存数据和磁盘数据不一致

### Redo Log Buffer

​		为了避免MySql宕机，导致内存中数据丢失，需要把对内存所作修改写入到Redo Log Buffer中去，这也是内存中的一个缓冲区，使用了存放redo日志的。``redo日志就是记录对数据做了什么修改``

​		如果此时MySql宕机，此时内存中的数据全部丢失，但是由于事务并没有更新，所以磁盘上的数据依旧是旧数据

### Redo落盘

​		提交事务时，需要根据一定策略将redo日志从redo log buffer中刷入磁盘。这个策略是通过 **innodb_flush_log_at_trx_commit** 来进行配置的。其刷盘策略有三种

> 参数为0：提交事务时，不会将redo log buffer中数据刷入磁盘。如果此时MySql宕机了，那么内存中数据会丢失
>
> 参数为1：提交事务时，必须把redo log从内存中刷到磁盘文件中去，只要提交事务成功，那么redo log就必然在磁盘里了。此时MySql若宕机，那么内存中的数据虽然丢失，但是redo log 文件得到保存，MySql可以根据redo日志去进行恢复
>
> 参数为2：提交事务时，把redo日志写入到磁盘os cache缓存中，等待刷入到磁盘中去。如此时MySql宕机，并且redo文件还停留带os cacha中，那么数据会丢失

​		因此，redo日志刷盘策略一般都选为1，保证事务提交之后，数据不会丢失

因为数据库的每一次更新SQL语句，都必然涉及到多个磁盘随机读取数据页的操作，也会涉及到一条redo log日志文件顺序写的操作。所以磁盘读写的IOPS指标，就是每秒可以执行多少个随机读写操作，以及每秒可以读写磁盘的数据量的吞吐量指标，就是每秒可以写入多少redo log日志，整体决定了数据库的并发能力和性能。

### Binlog日志

> ​	redo log是一种**偏向物理性质的重做日志**，他里面记录的是类似这样的东西：对那个数据页中的什么记录，进行了什么修改。并且redo log是InnoDB存储引擎特有的
>
> ​	而binlog叫归档日志，**记录的是偏逻辑性的日志**，类似于：对user表中的id=10的行数据进行了更新，更新后的值是什么，binlog是mysql server自己的日志文件，不是InnoDB所特有的

​	在提交事务的同时，也会把这次更新对应的binlog文件写入到磁盘中去。对于binlog也有不同的刷盘策略，由参数 **sync_binlog** 控制。

> 参数为0：提交事务时，将binlog日志写入磁盘os cache中，等待刷入磁盘。此时若宕机，数据会丢失。0为默认值
>
> 参数为1：提交事务时，强制将binlog日志写入到磁盘中去。

### 基于binlog和relo log完成事务提交

​		当binlog写入到磁盘文件中后，接着就完成最终的事务提交，此时会将更新对应的binlog文件名称和此次更新的binlog日志在文件中的位置都写入到redo log日志文件中去，同时在redo log日志文件里写入一个commit标记。此时，才算完成了事务的提交

​		在redo log中写入commit标记的意义在于：`保持redo log和binlog的一致。`因为只有redo log和binlog一致，才能确认本次事务提交成功。

### 后台IO线程将内存中数据刷入磁盘

​		MySql后台有一个IO线程，会在之后某时间，随机的将内存buffer pool中的修改后的脏数据给刷回到磁盘中的数据文件中去。哪怕宕机也不影响，因为redo log和binlog中留有记录，可自行恢复





![image-20210415151815139](img/image-20210415151815139.png)



**执行器是非常核心的一个组件，负责跟存储引擎配合完成一个SQL语句在磁盘和内存层面的全部数据更新操作**

在执行更新时，每条SQL语句，都会对应修改buffer pool中的缓存数据，写undo日志，写redo log buffer 等步骤；在提交事务时，一定会将redo log刷入磁盘，binlog刷入磁盘，完成redo log中的commit标记；最后，再由后台IO线程随机的将buffer pool中的脏数据刷入到磁盘中





# 生产层面

8核16G，一般每秒扛一两千请求是没有问题的

16核32G，每秒三四千一般也没问题

数据库的磁盘最后使用SSD固态硬盘（数据库需要执行IO操作）



QPS(QUERY PER SECOND)：每秒处理多少请求。对数据库而言，可理解为每秒处理多少SQL语句

TPS(TRANSCATION PER SECOND)：每秒可处理的事务量。可理解为每秒处理多少事务提交或回滚

## 压测指标

### IO相关

- **IOPS**：这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机IO读写请求。

  这个指标是很关键的，因为之前我们在数据库架构原理中讲解过，你在内存中更新的脏数据库，最后都会由后台IO线程在不确定的时间，刷回到磁盘里去，这就是随机IO的过程。如果说IOPS指标太低了，那么会导致你内存里的脏数据刷回磁盘的效率就会不高。

- **吞吐量**：指机器的磁盘存储每秒可以读写多少字节的数据量

  这个指标也是很关键的，因为大家通过之前的学习都知道，我们平时在执行各种SQL语句的时候，提交事务的时候，其实都是大量的会写redo log之类的日志的，这些日志都会直接写磁盘文件。所以一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。一般来说我们写redo log之类的日志，都是对磁盘文件进行顺序写入的，也就是一行接着一行的写，不会说进行随机的读写，那么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。

- **latency**：指向磁盘中写入一条数据的延迟

  这个指标同样很重要，因为我们执行SQL语句和提交事务的时候，都需要顺序写redo log磁盘文件，所以此时你写一条日志到磁盘文件里去，到底是延迟1ms，还是延迟100us，这就对你的数据库的SQL语句执行性能是有影响的。一般来说，当然是你的磁盘读写延迟越低，那么你的数据库性能就越高，你执行每个SQL语句和事务的时候速度就会越快。

### 其他指标

- **CPU负载**：CPU负载是一个很重要的性能指标，因为假设你数据库压测到了每秒处理3000请求了，可能其他的性能指标都还正常，但是此时CPU负载特别高，那么也说明你的数据库不能继续往下压测更高的QPS了，否则CPU是吃不消的。
- **网络负载**：这个主要是要看看你的机器带宽情况下，在压测到一定的QPS和TPS的时候，每秒钟机器的网卡会输入多少MB数据，会输出多少MB数据，因为有可能你的网络带宽最多每秒传输100MB的数据，那么可能你的QPS到1000的时候，网卡就打满了，已经每秒传输100MB的数据了，此时即使其他指标都还算正常，但是你也不能继续压测下去了。
- **内存负载**：这个就是看看在压测到一定情况下的时候，你的机器内存耗费了多少，如果说机器内存耗费过高了，说明也不能继续压测下去了。

### 压测工具和监控

​	[压测工具sysbench](https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e383c5357307_MjhluwMb/1?from=p_5e0c2a35dbbc9_MNDGDYba&type=6)

​	[监控工具Prometheus和Grafana](https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5e398efe3b8f9_XZOAxAmQ/1?from=p_5e0c2a35dbbc9_MNDGDYba&type=6)

​	

# Buffer Pool

buffer pool是数据库中必须要搞懂的一个核心组件，因为增删改查操作首先就是针对这个内存中的Buffer Pool里的数据执行的，同时配合了后续的redo log，刷磁盘等机制和操作

## Buffer Pool的数据结构

Buffer Pool默认大小为128MB，可以通过配置修改。本质就是数据库中的一个内存组件，由一大堆缓存页和描述数据块组成，然后加上各种链表(free,flush,lru)辅助其运行

~~~shell
[server]
innodb_buffer_pool_size=2147483648
~~~



### 数据页和缓存页

MySql对数据抽象出了一个**数据页**的概念，他将很多**行数据**放在了一个数据页中，每一页数据中放了很多行数据。所以buffer pool中的存放的是一个个的数据页

默认情况下，磁盘中存放的数据页的大小是16KB，也就是说一页数据包含了16KB的内容。Buffer Pool中存放的页数据又称之为缓存页，一个缓存页的大小和一个数据页的大小是一一对应的。

### 缓存页中的描述信息

对于每个**缓存页**，都会有一个**描述信息**，这个描述信息可以大体确认是用来描述这个缓存页的，一般包含：这个数据页的表空间，数据页的编号，这个缓存页在Buffer Pool中的内存地址以及一些别的信息。这些描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面。如下图

![image-20210415165620384](img/image-20210415165620384.png)

Buffer Pool中的描述数据大概相当于缓存页的大小的5%左右。假设设置的buffer pool大小是128MB，那么实际上真正的大小可能有130MB，因为他里面还含有每个缓存页中的数据

### Buffer Pool的初始化

数据库启动时，便会按照配置的buffer pool大小，再稍微加大一点，去向操作系统申请一块内存空间，作为buffer pool的内存区域。内存区域申请完毕后，数据库就会按照默认的缓存页的16KB大小和对应的800字节左右的描述数据的大小，在Buffer Pool中划分出一个一个的缓存页和对于的描述数据。但此时缓存页都是空的，什么都没有

## Free链表

### 链表结构

Buffer Pool中有一个**Free链表**设计，他是一个**双向链表结构**，每个节点就是一个**空闲缓存页的描述数据块的地址**，即只要有一个缓存页是空闲的，那么他的描述数据块就会被放入到这个free链表中

![image-20210415172352892](img/image-20210415172352892.png)

free链表中还有一个基础节点，指向链表的头尾节点，里面还存储了链表中有多少个描述数据块的节点，即空闲缓存页

### 占用空间

free链表本身，就是由Buffer Pool中的描述数据块组成，每个描述数据块中都有两块指针，free_pre和free_netx。分别指向自己的上一个free链表的节点，以及下一个free链表的节点。

对于free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面存放了free链表的头节点的地址，尾节点的地址，还有free链表中当前有多少节点

### 将数据读入到Buffer Pool

1. 首先从free链表中获取一个描述数据块，并根据数据库找到缓存页
2. 将磁盘上的数据读取到对应的缓存页中去，同时将相关描述信息写入到缓存页的描述数据块中。比如数据页所属表空间等信息。
3. 最后把描述数据库从free链表中去除

### 判断数据页是否缓存

`数据库中还会有一个哈希表数据结构，他会用表空间+数据页号，作为一个key，然后缓存页地址作为value`

当要使用数据页的时候，通过“表空间+数据页号”作为key去哈希表中查询一下，如果没有就读取数据页，如果有了，就说明已经缓存了

![image-20210416150325751](img/image-20210416150325751.png)

## Flush链表

结构和free链表类似，也是通过缓存页的描述数据块中的两块指针，让被修改过的缓存页的描述数据块，组成一个双向链表。凡是修改过的缓存页，都会将其数据块加入到flush链表中。flush的意思就是脏页，后续都是要将其flush刷新到磁盘上去的。

设计flush链表就是为了能够快速的将脏数据页中的数据刷回到磁盘中去。在更新缓存页的时候，通过变换缓存页中的描述数据块flush链表的尾指针，就可以把脏页的描述数据块组成一个双向链表，即flush链表，而且flush链表的基础节点会指向起始节点和尾巴节点。



## 缓存页的淘汰

如果所有的缓存页都被塞了数据，此时无法从磁盘上加载新的数据页到缓存页中去。那么就要淘汰一些缓存页——`即把一个缓存中修改过的数据，刷入到磁盘中去，然后将缓存页清空，再把新的数据页加载到空闲的缓存页中去`

### 缓存命中率以及LRU链表

淘汰缓存页时应尽可能选择使用率较少的缓存页，因此需要知道那些缓存页经常被访问，那些缓存页很少被访问。此时需要引入**LRU链表(Least Recently Used，最少使用)。**其数据结构和之前的Free链表，Flush链表类似，都是一个双向链表，节点均指向缓存页的描述数据块的地址



### 原始的LRU淘汰机制

> 大致工作原理：当我们从磁盘中**加载一个数据页到缓存页**时，就将这个缓存页的描述数据放入到LRU链表头部去，那么只有有数据的缓存页，都会在LRU链表中，而且最近被加载数据的缓存页，都会放到LRU链表的头部去。假设某个缓存页的描述数据在LRU链表的尾部，后续只要查询了或修改了这个缓存页，也会把这个缓存页挪动到LRU链表的头部，也就是**最近被访问过的缓存页，一定在LRU链表头部**
>
> 因此需要淘汰缓存页时，可以优先从LRU链表尾部进行淘汰

但这样的方式因为MySql的预读机制存在巨大隐患。

预读机制：当从磁盘上加载数据页的时候，MySql会连带着把这个数据页的相邻的其他数据页，都加载到缓存中去。

![image-20210416154211877](img/image-20210416154211877.png)

如果没有空闲缓存页了，此时加载新的数据页，就会将LRU链表尾部的数据淘汰。但这样是不合理的，毕竟其数据是有人访问的，而预读机制带入的数据页可能无人访问

> 一般而言，有两种情况可能触发MySql的预读机制
>
> - 有一个参数是innodb_read_ahead_threshold，他的默认值是56，意思就是如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓存里去
> - 如果Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去。这个机制是通过参数innodb_random_read_ahead来控制的，他默认是OFF，也就是这个规则是关闭的
>
> 预读机制可以一定程度上优化性能。如果你顺序读取很多数据页，MySql会判断可能会接着顺序读取后面的数据页。那么其提前读取到Buffer Pool中，后续读取就会方便很多

还有一种可能导致频繁被访问的缓存页被淘汰的情景：**全表扫描**（select *）

此时如果没where条件，那么会将表里全部数据页都从磁盘加载到Buffer Pool中去。此时LRU链表尾部，可能全部都是之前经常被访问的缓存页。此时进行淘汰时，就会将频繁访问的数据页给淘汰掉。

### 基于冷热数据分离思想设计LRU

真正的MySql在设计LRU链表时，采取的实际是**冷热数据分离**的思想。之前的问题，都是由于所有缓存页全部混在一个LRU链表中导致的

真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据。冷热数据比例由**innodb_old_blocks_pct**参数控制的，默认是37，即冷数据占比37%

**当数据页第一次加载到缓存时**：数据页第一次被加载到缓存时，缓存页会被放在**冷数据区域的链表头部**

**冷数据区域缓存何时被放入热数据区域**：**innodb_old_blocks_time 参数**，默认值是1000，即1000ms。也就是说必须是一个数据页被加载到缓存页之后，在1s之后，访问这个缓存页，才会被挪动到热数据区域的链表头部去

![image-20210416161307127](img/image-20210416161307127.png)

这样设计的话，预读机制以及全表扫描加载进来的一大批缓存页，都会放在LRU链表的冷数据区域的前面位置。而那些频繁访问的缓存页都被放在热数据区域。淘汰缓存时，直接淘汰冷数据区域尾部的缓存页，刷入磁盘即可。

在这样的设计机制下，原始的LRU淘汰机制的问题基本都被解决掉了。

`因为那种预读机制以及全表扫描机制加载进来的数据页，大部分都会在1s之内访问一下，之后可能就再也不访问了，所以这种缓存页基本上都会留在冷数据区域里。然后频繁访问的缓存页还是会留在热数据区域里。当你要淘汰缓存的时候，优先就是会选择冷数据区域的尾部的缓存页，这就是非常合理的了！他不会让刚加载进来的缓存页占据LRU链表的头部，频繁访问的缓存页在LRU链表的尾部，淘汰的时候淘汰尾部的频繁访问的缓存页了！`

**热数据区域的优化**：LRU链表中的热数据区域的访问规则进行了优化，即只有在热数据区域的后3/4区域的缓存页被访问了，才会移动到链表头部去，如果是前面1/4的区域被访问，是不会移动到链表头部的。这样减少了链表的移动。

### 定时将LRU尾部缓存页刷入磁盘

并不是在缓存页满时，才会将LRU冷数据区域尾部的缓存页刷入磁盘。而是有一个后台线程，会运行一个定时任务，每隔一段时间就会把LRU链表的冷数据尾部的缓存页刷入到磁盘中，清空缓存页，并将其加入Free链表中

### 把Flush链表的缓存页刷入磁盘

仅将LRU冷数据区域缓存页刷入磁盘是不够的，后台线程也会在**MySql不繁忙的时候，将flush链表中的缓存页刷入磁盘中**，这样修改过的数据，迟早也会刷入磁盘。只要flush链表的缓存页被刷入磁盘，那么缓存页也会从flush链表和lru链表中移除，然后加入到free链表中



### 总结

总之，MySQL在执行CRUD的时候，首先就是大量的操作缓存页以及对应的几个链表。然后在缓存页都满的时候，必然要想办法把一些缓存页给刷入磁盘，然后清空这几个缓存页，接着把需要的数据页加载到缓存页里去！

你的MySQL的内核参数，应该如何优化，优化哪些地方的行为，才能够尽可能的避免在执行CRUD的时候，经常要先刷一个缓存页到磁盘上去，才能读取一个磁盘上的数据页到空闲缓存页里来？

> 如果要避免上述问题，就要避免缓存页频繁的使用完毕。这里的关键点就在于buffer pool的大小（程序对于缓存页是使用，以及定时线程释放缓存页的过程很难去控制）
>
> buffer pool的大小以及buffer pool的数量，这些参数需要用心的设置和优化，因为他对MySql的性能和并发能力，由较大的影响。



## Buffer Pool的优化

### 多个Buffer Pool

多线程并发访问Buffer Pool时，如果访问的是一些共享数据，那么必然会进行锁操作。因此如果并发请求高的话，性能会受到影响

因此可以设置多个Buffer Pool来优化并发能力。MySql默认规则是，如果给Buffer Pool分配的内存小于1GB，那么就会分配一个Buffer Pool。如果分配的内存大，那么就可以设置多个Buffer Pool

~~~shell
# buffer pool总大小为8GB，4个buffer pool实例
[server]
innodb_buffer_pool_size = 8589934592
innodb_buffer_pool_instances = 4
~~~

这样多线程并发性能就会得到很大的提高

![image-20210416173751720](img/image-20210416173751720.png)

### 基于chunk机制动态调整Buffer Pool大小（不常用）

Buffer Pool是由很多**chunk**组成的，每个大小是由 **innodb_buffer_pool_chunk_size** 参数控制的，默认值是128MB。每个Buffer Pool里的每个chunk里就是一系列的描述数据块和缓存页，多个chunk共享一套free,flush,lru链表

![image-20210416174234597](img/image-20210416174234597.png)

基于chunk机制，就可以动态的调整buffer pool的大小了。如果需要增加Buffer Pool的大小，那么可以申请一系列的128MB大小的chunk就可以了，只要每个chunk是连续到128MB内存就可以，然后将申请到的chunk内存分配给Buffer Pool即可



## Buffer Pool的参数设置

一般buffer pool大小为机器内存的50%-60%之间即可

Buffer Pool总大小=（chunk大小 * buffer pool数量）的2的倍数

## SHOW ENGINE INNODB STATUS

![image-20210419094438495](img/image-20210419094438495.png)

![image-20210419094451591](img/image-20210419094451591.png)

## 总结

数据库在生产环境运行时，需要根据机器的内存设置合理的buffer pool大小，然后设置buffer pool的数量。这样的话，可以尽可能的保证数据库的高性能和高并发能力。

在线上运行的时候，buffer pool是由多个的，每个buffer pool中多个chunk共用一套链表数据结构。执行crud的时候，会不停的加载磁盘上的数据页到缓存页中，然后查询和更新缓存中的数据，同时维护一系列的链表结构。

然后后台线程定时根据lru链表和flush链表，去将一批缓存页刷入磁盘释放掉这些缓存页，同时更新free链表

如果执行curd时发现缓存页都满了，无法加载自己需要的数据页进行缓存，此时就将lru链表冷数据区域的缓存页刷入磁盘，然后加载自己需要的数据页进来。

大致原理就是如此。





# 物理数据结构

> 为何不直接更新磁盘上的数据——磁盘随机读写性能太差，如果直接更新磁盘文件，必然会导致数据无法承受高并发
>
> 为何进入数据页概念—— 一条一条加载数据到内存更新，效率太低。不如将数据组织成一页一页的概念，每次加载数据时，至少加载一页甚至多页数据。可以说**页**就是数据库的最小数据单位，默认为16KB大小。磁盘和内存直接的交换通过数据页来执行



## MySql物理存储格式

### 行格式

对一个表指定他的行存储格式是什么样的。eg：CREATE TABLE table_name (columns) ROW_FORMAT=COMPACT/ALTER TABLE table_name ROW_FORAMT=COMPACT

对于每一行数据，存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上他这一行数据的每一列的具体的值，这就是所谓的行格式。大致形式如下

> 变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......

其他几种行格式都大同小异。

### 变长字段在磁盘的存储

在存储每一行数据时，都保存其变长字段的长度列表，这样才能解决读取问题。如果有多个变长字段，则长度排放是逆序的。如果hello是VARCHAR(10)类型的变长字段的值，那么其在磁盘存储时，结构可能是这样的 0x05 null值列表 数据头 hello ...

> create table custom（name VARCHAR(10) NOT NULL  ,  address VARCHAR(20)  ,  gender CHAR(1)  ,  job VARCHAR(30)  ,  school VARCHAR(50)）ROW_FORMAT=COMPACT;
>
> 假设数据为 jack NULL m NULL xx_school。
>
> 如果变长字段为null值，就不用在变长字段列表里存放值长度了，上述数据中，只有name和school两个字段有值。将其长度按照逆序放在变长字段长度列表中即可      
>
> 0x09 0x04 NULL值列表 头信息...
>
> 

### NULL字段值在磁盘的存储

NULL值列表即一行数据中可能有的字段值为NULL，比如name字段，如果允许为NULL值，并且在实际存储时也没有赋值，那其字段值就为NULL。

但是NULL值在实际存储时，是不会按照字符串形式存放在磁盘上浪费空间的，null实际是以二进制bit位来存储的。

Null值列表是允许值为Null，只要是允许为null的字段，在NULL值列表中都会有一个bit位，bit值为1说明是NULL，为0说明不是NULL

 jack NULL m NULL xx_school数据中有4个字段允许为NULL，其中有两个为null，两个不为null。则4个bit位：1010。但其实逆序存放，实际上是0101。并且NULL值列表存放时，不会仅仅是4个bit位，他一般起码是8个bit位的倍数，不足8位就补0。所以实际存储时类似下面这种形式

**0x09 0x04 00000101 数据头信息 column01=value1，column02=value2，column0n=voluen......**

### 数据头的存储

40个bit为中，第一位和第二位都是预留位，没任何含义

第三个bit位是：**delete_mask**，其标识本行数据是否被删除

第四个bit位是：min_rec_mask，是否是B+Tree每一层的非叶子节点的最小值

接下来的4个bit位是：n_owned，记录数

接下来的13个bit位是：heap_no，代表当前这行数据在记录堆里的位置

接下来3个bit位的record_type，即这行数据的类型：0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据

最后是16bit位的next_record，指向下一条数据的指针

0x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school

### 实际数据的存储

实际上字符串是根据数据库指定的字符集编码，进行编码后再存储的，所以一行数据可能如下

0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262

在实际存储时，会在其真实数据部分加入一些隐藏字段：

- DB_ROW_ID：行唯一标识，数据库内部设置的一个标识，不是主键ID字段。如果没有指定主键和unique key唯一索引，他就会在内部自动加ROW_ID作为主键
- DB_TRX_ID：事务id，和事务有关
- DB_ROLL_PTR：回滚指针，用来进行事务回滚。

如果加上隐藏字段，实际一行数据可能如下

0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR）  616161 636320 6262626262

### 行溢出

数据页的默认大小为16KB，如果一行的数据存储内容太多(blob，text这种类型字段都有可能出现溢出)，一个数据页都放不下了，此时只能溢出这个数据页，把数据溢出存放到其他数据页中，那些数据页就叫做溢出页

![image-20210419155633644](img/image-20210419155633644.png)

## 数据页的结构

一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部。

![image-20210419160536834](img/image-20210419160536834.png)

其中文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节。

行数据会插入到缓存页的空闲区域（数据页和缓存页是一一对应的）中，并最终被刷入到磁盘中

## 表空间和数据区

平时创建的表，都有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的磁盘数据空间。在物理层面，表空间就是对应一些磁盘上的数据文件。有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个“表名.ibd”数据文件。

一个表空间里的数据页太多了，不便于管理，于是引入**数据区（extent）**的概念，一个数据区对应着连续的64个数据页，每个数据页是16KB，所以一个数据区是1mb，然后256个数据区被划分为一组。

**对应表空间而言，他的第一组数据区的前三个数据页都是固定的，存放了一些描述性的数据。表空间的其他组数据区的第一个数据区的前两个数据页，也是存放特殊信息的**

**我们平时创建的那些表都是有对应的表空间的，每个表空间就是对应了磁盘上的数据文件，在表空间里有很多组数据区，一组数据区是256个数据区，每个数据区包含了64个数据页，是1mb**

当我们需要执行crud操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用。

![image-20210419162102028](img/image-20210419162102028.png)

# IO调度

## LINUX层面读写

简单来说，Linux的存储系统分为VFS层、文件系统层、Page Cache缓存层、通用Block层、IO调度层、Block设备驱动层、Block设备层，如下图：

![image-20210419165915585](img/image-20210419165915585.png)

当MySQL发起一次数据页的随机读写，或者是一次redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给Linux操作系统的VFS层。这一层的作用，就是根据你是对哪个目录中的文件执行的磁盘IO操作，把IO请求交给具体的文件系统。

举个例子，在linux中，有的目录比如/xx1/xx2里的文件其实是由NFS文件系统管理的，有的目录比如/xx3/xx4里的文件其实是由Ext3文件系统管理的，那么这个时候VFS层需要根据你是对哪个目录下的文件发起的读写IO请求，把请求转交给对应的文件系统，如下图所示。

接着文件系统会先在Page Cache这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读写，如果没有就继续往下一层走，此时这个请求会交给通用Block层，在这一层会把你对文件的IO请求转换为Block IO请求。

接着IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这一层里默认是用CFQ公平调度算法的，也就是说，可能假设此时你数据库发起了多个SQL语句同时在执行IO操作。有一个SQL语句可能非常简单，比如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的一个block里的数据就可以了。但是有的SQL语句，比如说select * from xx where xx1 like "%xx%"可能需要IO读取磁盘上的大量数据。那么此时如果基于公平调度算法，就会导致他先执行第二个SQL语句的读取大量数据的IO操作，耗时很久，然后第一个仅仅更新少量数据的SQL语句的IO操作，就一直在等待他，得不到执行的机会。

所以在这里，**其实一般建议MySQL的生产环境，需要调整为deadline IO调度算法，他的核心思想就是，任何一个IO操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。**

此时IO请求被转交给IO调度层

最后IO完成调度之后，就会决定哪个IO请求先执行，哪个IO请求后执行，此时可以执行的IO请求就会交给Block设备驱动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，如下图所示。然后硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上面的层级反向依次返回，最终MySQL可以得到本次IO读写操作的结果。

## RAID存储架构

RAID就是一个磁盘冗余阵列，可以大致理解为用来**管理机器里的多块磁盘的一种磁盘阵列技术**。有了它，在向磁盘中读写数据时，他会告诉你应该在那块磁盘上读写数据。并且其还实现了**数据冗余机制**，所以其实有的RAID磁盘冗余阵列技术里，是可以把你写入的同样一份数据，在两块磁盘上都写入的，这样可以让两块磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的，不需要你操心。

![image-20210419170918602](img/image-20210419170918602.png)

服务器使用多块磁盘组成的RAID阵列的时候，一般会有一个RAID卡，这个RAID卡是带有一个缓存的，这个缓存不是直接用我们的服务器的主内存的那种模式，他是一种跟内存类似的SDRAM，当然，你大致就认为他也是基于内存来存储的吧！然后我们可以把RAID的缓存模式设置为write back，这样的话，所有写入到磁盘阵列的数据，先会缓存在RAID卡的缓存里，后续慢慢再写入到磁盘阵列里去，这种写缓冲机制，可以大幅度提升我们的数据库磁盘写的性能。

RAID卡一般都配置有自己独立的锂电池或者是电容，如果服务器突然掉电了，无法接通电源了，RAID卡自己是基于锂电池来供电运行的，然后他会赶紧把缓存里的数据写入到阵列中的磁盘上去。

# redo和undo

## redo log

redo log的本质是为了保证事务提交后，修改的数据绝对不会丢失（在提交事务的时候，保证把对缓存页做的修改以日志的形式写入到redo log日志文件中去）

**相比将修改后的缓存页刷入磁盘，写redo log性能更好更快（写入文件小，顺序写入磁盘文件），可以提供并发能力**

redo log中记录内容：**表空间号+数据页号+偏移量+修改几个字节的值+具体的值**

根据修改了数据页中几个字节的值，redo log被划分为了不同的类型，MLOG_1BYTE类型的日志代表修改了一个字节的值；MLOG_2BYTE类型的日志代表修改了两个个字节的值。如果一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，代表一下子在那个数据页的某个偏移量的位置插入或者修改了一大串的值。redo log内容大致如下

日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，具体修改的数据	

### redo log block

MySql内部数据结构  redo log block。一个redo log block是512字节，这个redo log block的512字节分为三个部分，一个是12字节的header块头，一个是496字节的body块体，一个是4字节的trailer块尾。

其中12字节的head头又可细分

1. 包括4个字节的block no，就是块唯一编号；
2. 2个字节的data length，就是block里写入了多少字节数据；
3. 2个字节的first record group。这个是说每个事务都会有多个redo log，是一个redo log group，即一组redo log。那么在这个block里的第一组redo log的偏移量，就是这2个字节存储的；
4. 4个字节的checkpoint on

![image-20210420145606073](img/image-20210420145606073.png)

对于redo log而言，他确实是不停的追加写入到redo log磁盘文件中去，但每一个redo log都是写入到文件中的一个redo log block中去的，一个block最多存放496自己的redo log日志。

![image-20210420145957691](img/image-20210420145957691.png)

### redo log buffer

redo log buffer是MySql启动时申请的一片连续内存，然后里面划分出了N多个空的redo log block。通过MySql的innodb_log_buffer_size可以指定其大小，默认值是16MB。

一个事务涉及的多个redo log 会组成一个redo log group，一起写入redo log block中

![image-20210420151724195](img/image-20210420151724195.png)

### 刷入磁盘的时机

redo log在写的时候，都是一个事务组里的一组redo log，先暂存在一个地方，完事后把一组redo log写入redo log buffer。写入redo log buffer时，是写入里面提前规划好的一个一个的redo log block中，选择有空闲空间的redo log block去写入，然后redo log block写满之后，会在某个时机刷入磁盘中

- 如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在缓冲里了，此时就会把他们刷入到磁盘文件里去
- 一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改（PS：之前最早最早的时候，讲过，这个redo log哪怕事务提交的时候写入磁盘文件，也是先进入os cache的，进入os的文件缓冲区里，所以是否提交事务就强行把redo log刷入物理磁盘文件中，这个需要设置对应的参数)
- 后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去
- MySQL关闭的时候，redo log block都会刷入到磁盘里去

为保证数据不丢失，还需要配置参数，提交事务把redo log刷入磁盘文件的os cache后，还得强行从os cache刷入物理磁盘

还可以**通过innodb_log_group_home_dir参数设置redo log写入文件目录，innodb_log_flie_size可以指定redo log文件大小，默认是48MB，通过innodb_log_files_in_group可以指定日志文件数量，默认就两个**

因此默认情况下，目录中就两个日志文件，每个48MB，先写第一个，再写第二个。如果第二个写满了，重新覆写第一个即可。96MB得日志文件够存储上百万条redo log了

## undo log回滚日志

执行事务的时候，里面很多INSERT、UPDATE和DELETE语句都在更新缓存页里的数据，但是万一事务回滚，你必须有每条SQL语句对应的undo log回滚日志，根据回滚日志去恢复缓存页里被更新的数据。

执行了INSERT语句，那么undo log必须有插入数据的主键ID，可以在回滚的时候从缓存页里把这条数据给删除了；

执行了DELETE语句，那么undo log必须记录下来被删除的数据，回滚的时候就得重新插入一条数据；

执行了UPDATE语句，那么undo log必须记录下来修改之前的数据，回滚的时候就得把数据给更新回去；

![image-20210420161118604](img/image-20210420161118604.png)

### undo log内容

以insert为例。insert语句的undo log类型是TRX_UNDO_INSERT_SEC，其中包含了以下一些东西

- 日志的开始位置
  - 主键的各列长度和值（如果自己指定主键，那么主键可能是多个列。主键各列长度和值，意思是插入这条数据的主键的每个列，长度是多少，具体值是多少。即使没有设置主键，MySql也会自己设置row_id作为隐藏字段，作为主键）
- 表id
- undo log日志编号
- undo log日志类型
- 这条日志的结束位置

![image-20210420162227241](img/image-20210420162227241.png)

如果事务回滚了，就就找出语句对于的undo log，根据undo log就可以定位数据，执行回滚



# 事务



## 脏写，脏读，不可重复读，幻读

### 脏写

即两个事务同时执行，A事务更新一条数据后，B事务由更新了同一条数据。此时A事务回滚，将更新数据改回最初值。对于事务B来说，其更新值丢失。这即为脏写

### 脏读

即两个事务同时执行，A事务更新一条数据后，B事务查询该数据。此时A事务回滚，将更新数据改回最初值。对于事务B来说，再次查询发现值变了。这即为脏读

**无论是脏写还是脏读，都是因为一个事务去更新或者查询了另外一个还没提交的事务更新过的数据。因为另外一个事务还没提交，所以他随时可能会反悔会回滚，那么必然导致你更新的数据就没了，或者你之前查询到的数据就没了，这就是脏写和脏读两种坑爹场景。**

### 不可重复读

在事务执行期间，事务A在事务执行期间，读到了事务B和事务C提交事务修改的值。对事务A来言，在事务未提交时，多次重复读取，所读的值不同，这就是不可重复读

不可重复读取决于你想要数据库是什么样子的，如果你希望看到的场景就是不可重复读，也就是事务A在执行期间多次查询一条数据，每次都可以查到其他已经提交的事务修改过的值，那么就是不可重复读的，如果你希望这样子，那也没问题。

### 幻读

事务A需要查询一批数据出来如：select * from table where id > 10 。查询出了10条数据，此时事务B向表中插入两条数据，并提交事务。此时事务A再次按照同样进行查询，会导致查询出12条数据

幻读特指查询到了之前查询没看到的数据

## 隔离级别

**read uncommitted（读未提交），read committed（读已提交），repeatable read（可重复读），serializable（串行化）**

### read uncommitted（读未提交）

不允许发生脏写。不可能有两个事务在没提交的情况下去更新同一行数据的值。但此隔离级别会发生 脏读，不可重复读，以及幻读

### read committed（读已提交）RC

不会发生脏读和脏写。即事务未提交情况下修改的值，不会被另一事务读到。但可能发生不可重复读和幻读

### repeatable read（可重复读）RR

这个级别下，不会发生脏写、脏读和不可重复读的问题，因为你一个事务多次查询一个数据的值，哪怕别的事务修改了这个值还提交了。你事务一旦开始，多次查询一个值，会一直读到同一个值！

RR隔离级别，保证了对同一行数据的多次查询，但还是有幻读问题

### serializable（串行化）

不允许事务并发执行，只能串行执行

# MVCC多版本并发控制机制

## undo log版本链

> 每条数据都有两个隐藏字段：**trx_id和roll_pointer**。trx_id是最近一次更新这条数据事务的id，roll_pointer指向了**更新这个事务之前**生成的undo log

![image-20210420173039621](img/image-20210420173039621.png)

如上图，事务A插入一条数据，此条数据的隐藏字段以及指向undo log如图所示。roll_pointer指向为空，因为之前是没有的

![image-20210420173049746](img/image-20210420173049746.png)

假设事务B修改了数据的值为B，则数据的隐藏字段也相应进行改别

![image-20210420173059505](img/image-20210420173059505.png)

事务C又对数据进行修改，则隐藏字段变动关系如图

**多个事务串行执行的时候，每个事务修改了数据后，都会更新隐藏字段trx_id和roll_pointer，同时之前的多个数据快照对应的undo log，会通过roll_pointer指针串联起来，形成重要的版本链**

## ReadView机制（基于undo log版本链）

ReadView，简单的说，就是在执行一个事务的时候，就会生成一个ReadView。其中里面比较关键的东西有4个

- m_ids，此时有那些事务在MySql里执行还没提交的；
- min_trx_id，就是m_ids中最小的值；
- max_trx_id，就是MySql下一个要生成的事务id，即最大事务id；
- creator_trx_id，当前事务id；

**其可以保证当前事务可以读取到事务开启前，别的事务提交的更新的值，以及自己事务更新的值（此即实现了RR隔离级别）**





当前有两个事务A和B，B去更新数据，A去读取数据。

![image-20210420174246158](img/image-20210420174246158.png)

事务A开启ReadView后，当前ReadView包含事务A和事务B的id（45，59）。min_trx_id就是45，max_trx_id是60，creator_trx_id是事务Aid：45	

事务A第一次查询时，会进行判断，判断当前这行数据的trx_id是否小于当前ReadView的min_trx_id。如果小于，说明事务开启之前，修改这行数据的事务就已经提交，此时可以查到这行数据。

此时事务B，更新了这条数据，此时这行数据的trx_id变为59。然后事务B就提交了

![image-20210420174947442](img/image-20210420174947442.png)

此时A再次查询，会发现此时数据行里的trx_id为59，大于当前ReadView中的min_trx_id，同时小于max_trx_id。这说明更新这条数据的事务，可能和自己是同时开启的，因此便会查看m_ids，查看trx_id=59是否存在其中。发现存在便不能对其进行查询。

![image-20210420175325097](img/image-20210420175325097.png)

于是，便通过roll_pointer顺着undo log版本链查找，查找符合要求的undo log。这就是undo log版本链的作用，其可以保存一个快照链条，让事务读取到之前的快照值

接着，事务A更新了这行数据的值，trx_id修改为了45，同时保存之前事务B修改的值的快照。此时事务A再次查询

![image-20210420213304037](img/image-20210420213304037.png)

在事务A执行的同时，事务C更新了这行数据的值，还提交了。此时事务A再去查询，发现当前数据的trx_id为78，大于了自己ReadView中的max_trx_id(60)。说明事务A开启之后，又有一个事务提交了数据，自己是看不到的。只能通过undo log链条去寻找可读到的版本

![image-20210420213541453](img/image-20210420213541453.png)

## RC(read committed)隔离级别和ReadView

RC隔离级别指事务运行期间，只要别的事务修改数据提交了，就可以读到其他事务修改的数据，所以会发生不可重复读，幻读问题

**当一个事务设置处于RC隔离级别时，他每次发起查询，都会重新生成一个ReadView**



假设当前有两个事务A,B。事务B发起update操作，更新了一条数据，将其修改为B。此时数据对应的事务id为70，同时生成一个undo log

![image-20210420215725580](img/image-20210420215725580.png)



此时，事务A要发起查询操作，会生成一个ReadView，此时ReadView里的min_trx_id=60，max_trx_id=71，creator_trx_id=60，此时如下图所示。

![image-20210420215838287](img/image-20210420215838287.png)

此时只能查到undo log版本链中的数据。如果此时事务B提交，那么事务B就不属于活跃事务了。此时A再进行查询，就会重新生成一个ReadView

![image-20210420220022760](img/image-20210420220022760.png)

此时事务A就可以查询到事务B了



## RR(read repatable)隔离级别和ReadView

在MySql中，RR隔离级别是可以同时避免不可重复读和幻读问题的。在RR级别下，事务读一条数据，无论是读取多少次，都是一个值，别的事务修改数据之后哪怕提交了，也是看不到其他事务的修改数据的。同时如果其他事务插入了一些数据，也是感知不到的



假设有如下事务A，B和数据

![image-20210420220515025](img/image-20210420220515025.png)

此时事务A基于这个ReadView去查这条数据，会发现这条数据的trx_id为50，是小于ReadView里的min_trx_id的，说明他发起查询之前，早就有事务插入这条数据还提交了，所以此时可以查到这条原始值的，如下图。

![image-20210420220546294](img/image-20210420220546294.png)

此时事务B更新此条数据的值为B，同时修改trx_id为70，并生成undo log。并提交了事务

此时，事务A中的ReadView中的m_ids还是[60，70]。因为ReadView一旦生成就不会轻易改变。虽然事务B结束了，但在A的ReadView中还是会有两个事务id

此时事务A再次去查询数据的值，此时数据的trx_id为70，70一方面是在ReadView的min_trx_id和max_trx_id的范围区间的，同时还在m_ids列表中

![image-20210420222131378](img/image-20210420222131378.png)

事务A多次读同一个数据，每次读到的值都是一样的，除非其自己修改了值。因为事务A的ReadView始终是不变的，它基于这个ReadView查到的值是一样的

这样就解决了不可重复读的问题



事务C此时插入了一条数据，并进行事务的提交。接着，事务A进行查询，此时会发现符合条件的有两条数据，一条是原始值数据，一条是事务C插入的那条数据。但是事务C插入的那条数据的trx_id是80，这个80是大于自己的ReadView的max_trx_id的，说明这条数据是不能进行查询的

![image-20210420222359449](img/image-20210420222359449.png)

因此，事务A进行查询还是只能查询到一条数据。所以事务A不会发生幻读，他根据条件范围查询的时候，每次读到的数据都是一样的，不会读到其他事务插入的数据，这都是基于ReadView机制实现的

## 总结

> 多个事务并发运行的时候，同时读写一个数据，可能会出现脏写、脏读、不可重复读、幻读几个问题
>
> 所谓的脏写，就是两个事务都更新一个数据，结果有一个人回滚了把另外一个人更新的数据也回滚没了。
>
> 脏读，就是一个事务读到了另外一个事务没提交的时候修改的数据，结果另外一个事务回滚了，下次读就读不到了。
>
> 不可重复读，就是多次读一条数据，别的事务老是修改数据值还提交了，多次读到的值不同。
>
> 幻读，就是范围查询，每次查到的数据不同，有时候别的事务插入了新的值，就会读到更多的数据。
>
> 针对这些问题，才会有RU,RC,RR和串行四个隔离级别
>
> RU隔离级别，就是可以读到人家没提交的事务修改的数据，只能避免脏写问题；
>
> RC隔离级别，可以读到人家提交的事务修改过的数据，可以避免脏写和脏读问题。
>
> RR是不会读到别的已经提交事务修改的数据，可以避免脏读、脏写和不可重复读的问题；
>
> 串行是让事务都串行执行，可以避免所有问题。
>
> 然后MySQL实现MVCC机制的时候，是基于**undo log多版本链条+ReadView机制**来做的，默认的RR隔离级别，就是基于这套机制来实现的，依托这套机制实现了RR级别，除了避免脏写、脏读、不可重复读，还能避免幻读问题。





# 锁机制

> 不是太建议在数据库粒度去通过行锁实现复杂的业务锁机制，而更加建议通过redis、zookeeper来用分布式锁实现复杂业务下的锁机制，其实更为合适一些。

## 锁机制入门

依靠锁机制可以让多个事务更新一行数据的时候串行化，避免同时更新一行数据

一个事务要对一个数据进行更新时，事务会判断当前数据是否有锁，如果没有锁，该事务就会创建一个锁，里面包含了事务的trx_id和等待状态，然后锁便和这行数据关联到了一起

更新一行数据必须把其所在的数据页从磁盘文件里读取到缓存页里才能更新。所以，此时和**这行数据相关的锁数据结构都是在内存中的**



![image-20210420223646003](img/image-20210420223646003.png)

如上图，事务A对数据加速的情况下，事务B也来更新数据，便也会生成锁，并进入排队状态。如果事务A修改完毕，便会将锁释放掉，并去判断是否有其他事务也对数据进行锁操作。如果有，便会修改下个等待锁的状态，并将其唤醒

![image-20210420223756352](img/image-20210420223756352.png)



## 共享锁和独占锁(行锁)

多个事务同时更新数据的时候，加的是X锁——Exclude独占锁，当有一个事务加了独占锁之后，此时其他数据再要更新这行数据，都要加独占锁，但要生成独占锁在后面等待。

当有事务在更新数据，其他事务读取该数据，是不需要加锁的。在默认情况下，有人更新数据时，其他事务读取数据，默认是开启MVCC机制的。其他事务读取数据，可以根据ReadView，去undo log版本链中找到一个你能读取的版本，不需要考虑别人在不断更新

MVCC机制就是避免频繁加锁互斥而设计的



查询时加锁（S锁，共享锁），可以通过：select * from table lock in share mode。在一个查询语句后加**lock in the share mode**，意思是查询的时候对一行数据加**共享锁**。

并且共享锁和独占锁是互斥的



| 锁类型 | 独占锁 | 共享锁 |
| :----: | :----: | :----: |
| 独占锁 |  互斥  |  互斥  |
| 共享锁 |  互斥  | 不互斥 |



查询操作也可以加互斥锁，select * from table for update

`所以这里可以先看出一个规律，就是更新数据的时候必然加独占锁，独占锁和独占锁是互斥的，此时别人不能更新；但是此时你要查询，默认是不加锁的，走mvcc机制读快照版本，但是你查询是可以手动加共享锁的，共享锁和独占锁是互斥的，但是共享锁和共享锁是不互斥的，如下规律。`



## 表级锁（了解即可）

表锁比较鸡肋，很少使用。表锁分为两种，一种为表锁，一种为表级的意向锁。并且执行DDL语句时，会阻塞所有增删改操作；执行增删改操作时，会阻塞DDL操作

LOCK TABLES xxx READ：这是加表级共享锁

LOCK TABLES xxx WRITE：这是加表级独占锁



还有另两种情况会加表级锁。如果有事务在表里执行增删改操作，那在行级会加独占锁，此时也会在表级加意向独占锁；如果有事务在表里执行查询操作，那么会在表级加意向独占锁



手动加表级共享锁和独占锁，以及更新和查询的时候自动在表级加的意向共享锁和意向独占锁，他们之间反而是有一定的互斥关系，关系如下表所示。

|   锁类型   | 独占锁 | 意向独占锁 | 共享锁 | 意向共享锁 |
| :--------: | :----: | :--------: | :----: | :--------: |
|   独占锁   |  互斥  |    互斥    |  互斥  |    互斥    |
| 意向独占锁 |  互斥  |   不互斥   |  互斥  |   不互斥   |
|   共享锁   |  互斥  |    互斥    | 不互斥 |   不互斥   |
| 意向共享锁 |  互斥  |   不互斥   | 不互斥 |   不互斥   |



其实更新数据自动加的表级意向独占锁，会跟你用 LOCK TABLES xxx WRITE 手动加的表级独占锁是互斥的，所以说，假设你手动加了表级独占锁，此时任何人都不能执行更新操作了！

或者你用LOCK TABLES xxx READ手动加了表级共享锁，此时任何人也不能执行更新操作了，因为更新就要加意向独占锁，此时是跟你手动加的表级共享锁，是互斥的！



**一般来讲，都是对同一行数据的更新操作加的行级独占锁是互斥，跟读操作都是不互斥的，读操作默认都是走mvcc机制读快照版本的！**



# 索引



# 实战